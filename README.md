# ğŸ§  DocIntel Agent â€“ Multi-Document Q&A with LLMs

A powerful GenAI-based document assistant that can read, chunk, embed, and answer questions across multiple PDF/DOCX files. Built with **LangChain**, **Gemini Pro**, **HuggingFace Embeddings**, and **Streamlit**.

> â€œUpload documents. Ask questions. Get answers with sources.â€

---

## ğŸš€ Features

- ğŸ“„ Upload multiple PDF & DOCX documents
- ğŸ§  Extract text, OCR fallback for scanned docs
- ğŸ§© Chunk + embed using `all-MiniLM-L6-v2` (local)
- ğŸ” RAG pipeline with Gemini LLM
- ğŸ¤– Ask complex questions and get reliable answers
- ğŸ“š See source snippets for each response
- ğŸ–¥ï¸ Easy-to-use Streamlit UI

---

## ğŸ› ï¸ Tech Stack

| Component    | Tool                                  |
|--------------|----------------------------------------|
| Frontend     | Streamlit                              |
| Backend      | Python + LangChain                     |
| LLM          | Gemini Pro (via `langchain-google-genai`) |
| Embedding    | HuggingFace (`all-MiniLM-L6-v2`)       |
| Vector Store | FAISS                                  |
| OCR          | Tesseract + pdf2image (for scanned PDFs) |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/docintel-agent.git
cd docintel-agent
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

GOOGLE_API_KEY=your_gemini_api_key_here

streamlit run app.py
